# 面试总结

### http方法的安全/幂等

1. 方法本身：GET不发送请求体，所以相对POST是安全的
   1. GET方法并不是强制不能带包体，只是部分包/库进行了限制
2. 对服务来说：
   1. ![HTTP方法安全性](H:\go\markdown\面试\img\HTTP方法安全性.jpg)
   2. 多次请求，对服务器来说没有状态改变，则该方法是安全的。
      1. 就是所谓的请求是幂等的，幂等指的是结果而不是请求到的资源本身
      2. 在编程中，同一方法多次运算，得到的结果是一致的，就可以说方法是幂等的，也就是安全的

### utxo 和balance 

1. utxo

   > Unspent  Transcation Output  ，即未花费的交易输出，其实没有什么比特币，只有utxo，比特币钱包就是代为统计这些utxo
   >
   > transcation 交易在比特币系统中简称tx，交易就是utxo的销毁和生成的过程，生成的时候提供锁定脚本，解锁时提供解锁脚本
   >
   > utxo模型允许并行交易的存在，系统追踪的是utxo的销毁和生成，而不是谁将比特币转给谁
   >
   > 核心思想：写入的数据不可变，通过哈希指针连接不同交易的输入输出，保证交易的合法性
   >
   > 好处：
   >
   > 1. 可扩展性：可以支持同时处理多个UTXO，所以可以实现并行事务并鼓励可伸缩创新
   > 2. 隐私，为每笔交易创建新的地址，可以提供高级别的安全性

2. 账户余额模型（balance）

   > 每个账户的余额保持为全球状态，检查账户余额确保大于或等于支出的金额
   >
   > 使用交易中的nonce（每次支付自增1） 来防止双重支付
   >
   > 抽象看eth，只有三种对象：账户，交易，区块
   >
   > 优势：
   >
   > 1. 实现简单
   > 2. 验证时效率较高
   >    1. 交易的输入输出都是地址，存储空间也小
   > 3. 创建交易不需要对UTXO签名，所以可以从任意一个节点同步区块，便于编写轻量级客户端

### solidity safemath

> 防止计算溢出造成代币超发，
>
> https://github.com/OpenZeppelin/openzeppelin-solidity/blob/master/contracts/math/SafeMath.sol

### mysql

1. 隔离级别

   > | 事务隔离级别                 | 脏读 | 不可重复读 | 幻读 |
   > | ---------------------------- | ---- | ---------- | ---- |
   > | 读未提交（read-uncommitted） | 是   | 是         | 是   |
   > | 读已提交（read-committed）   | 否   | 是         | 是   |
   > | 可重复读（repeatable-read）  | 否   | 否         | 是   |
   > | 串行化（serializable）       | 否   | 否         | 否   |
   >
   > innodb  rr级别的隔离主要通过mvcc实现，可以重复读，但无法防止幻读

2. MVCC(多版本并发控制)

   > 连接数据库的操作，在某个瞬间看到的都是数据库的一个快照
   >
   > innodb的行锁定依靠该机制实现
   >
   > innodb的MVCC不同于经典MVCC，在进行写操作的时候，使用了排他锁
   >
   >  	1. 经典MVCC不使用锁，完全依赖多版本记录进行控制
   >  	2. 当对同一记录多次操作后，对不是最近一次操作实施回滚操作，传统MVCC会覆盖该操作后面的动作，造成数据污染
   >
   > innodb中MVCC通过undo.log实现，
   >
   > innodb在存放数据时，会存放几个隐藏字段：
   >
   >  	1. DATA_ROLL_PTR
   >       ​	1. 指向回滚用的版本 --- undolog  日志记录
   >  	2. DATA_TRX_ID
   >       ​	1. 最近更新数据的事务ID
   >  	3. DB_ROW_ID
   >  	4. DELETE_BIT
   >       ​	1. 标识被删除
   >
   > 执行过程：
   >
   > Begin --> 使用排他锁 --> 写入redolog   -->   记录undolog  -->  修改内存中数据，事务编号等   --> commit阶段刷入binlog日志（prepare阶段），刷入事务日志

3. redolog

   > redolog日志是物理日志，所以对同一条数据的操作是幂等的
   >
   > redolog  是物理日志，所以恢复速度远远快于binlog日志
   >
   > 三个位置：
   >
   > 1. buffer redo(用户空间)
   > 2. os redo(内核空间)
   > 3. file  redo(文件系统)
   >    1. innodb_flush_log_at_trx_commit = 1 ,表示每次commit提交，就将redolog刷入磁盘
   >    2. innodb_flush_log_at_trx_commit = 0，每秒将buffer写入os redo，然后刷入磁盘，每次commit不会写入os redo
   >    3. innodb_flush_log_at_trx_commit = 2，每次提交都写入os redo，每秒调用fsync写入磁盘
   >    4. 生产中常设为2， 这样兼容了安全性和效率（buffer--> os  内存之间转移，很快）

4. undolog

   > 两个功能：
   >
   > 1. 提供回滚
   >    1. 理解为，事务中的每次操作，都会在undolog中记录一条用于回滚的相反操作（update主键时特殊，这时是相当于两条操作，先删除，再插入）
   > 2. 提供MVCC机制
   >    1. 当读取记录时，记录被其他事务读锁定，通过undolog中记录可获取锁定前的数据，从而提供该行版本信息
   >    2. 事务提交时，undolog并不会被立即删除，因为有可能被其他事务锁定，只要该行版本还被引用，就不能删除
   >
   > 属于逻辑日志：
   >
   > 默认存放在ibdata1中

5. binlog

   > binlog日志是上层系统的日志，redolog undolog都是innodb引擎生成的日志

6. commit

   >  group commit
   >
   > 一样先刷二进制，再刷事务日志
   >
   > commit阶段开始commit  prepare时，为了保证二进制日志和事务日志的顺序性，使用一个独占锁进行控制，破坏了group commit
   >
   > mysql5.6以后，改进为通过一个队列存放事务，commit阶段保证顺序性

7. 双主架构

   > 通过配置主主赋值 + keepalived 实现
   >
   > 关键点：
   >
   > 1. 两个节点的auto_increment_increment（自增步长）和auto_increment_offset（自增起始值）设为不同值
   > 2. keepalived 设定为抢占模式，防止脑裂后网络恢复后出现VIP不释放的状况
   > 3. 为防止从服务器同步延迟，可以使用mysql5.7以上版本，提供了多线程复制

8. 分库分表

   > 业务分库
   >
   > 1. 按照业务对表进行拆分，可以存放于不同实例，回导致join无法使用
   >
   > 垂直切分
   >
   >  	1. 按字段条件切分
   >  	2. 按范围切分
   >  	3. 取模切分
   >       ​	1. 这种切分扩容会很麻烦，推荐倍数扩容
   >
   > 数据库分区
   >
   >  	1. 数据库自身的特性
   >
   > 带来的问题：
   >
   > 1. 分库分表时的复杂性
   > 2. 数据库架构变复杂
   > 3. 跨节点无法join
   > 4. 扩容/数据迁移艰难
   >    1. 推荐业务双写迁移
   >       1. 上线双写业务  -->   迁移就数据  -->  验证迁移数据 -->  切换读路由  --> 下线双写业务
   >       2. 要明确什么样角色的什么人在什么时候到什么系统看到什么样的数据，才能确认迁移成功。
   >    2. https://blog.csdn.net/qq_16605855/article/details/80966363
   >    3. 停机迁移
   >    4. 迁移后的数据清洗：
   >       1. 能全量对比，就全量对比，不能就抽样对比
   >       2. 通过服务日志，判定数据不一致的原因
   >       3. 可能的原因：
   >          1. 更新/删除数据最容易产生问题，迁移某条数据时，正在进行操作，迁移系统已获取数据，两方同时进行了修改，然后迁移系统又对数据进行了修改，造成数据不一致，通过binlog日志timestamp进行区分

9. 宕机回滚

   >```
   >1. 扫描日志，找出所有已经START,还没有COMMIT的事务。
   >2. 针对所有未COMMIT的日志，根据redo log来进行回滚。 
   >```

10. checkpoint

    > 将内存中的脏数据/脏日志刷入磁盘

11. innodb回滚操作

    > 不管开机前是否是正常关机，开机后，系统都会进行恢复行为
    >
    > checkpoint表示之前的操作都已经刷入磁盘，所以仅需从checkpoint开始的位置开始恢复
    >
    > 如果宕机时，正在checkpoint，刷盘数据页中记录的LSN大于日志页中的LSN，不需要重做

12. sql

    > 1. select singer_id, group_concat(song_id) from song_singer group  by singer_id;
    >
    > 2. select singer.id, singer.singer_name, sum(song_stats.listen_count) from song_stats inner join song_singer on song_stats.song_id = song_singer.song_id inner join singer on song_singer.singer_id = singer.id inner join song on song_stats.song_id = song.id group by song_singer.singer_id having sum(song_stats.listen_count) > 100;
    > 3.  select uid from   (select uid,sum(score),date from test1 group by uid,date having sum(score) > 10 ) as subtable group by uid having count(uid) > 0
    > 4. select date_add("2018-11-11", interval 1 day)
    > 5. select date_format(now(), '%m-%d-%Y')     date 五种类型：date  time  datetime timestamp  year
    > 6. VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则 使用两个字节)

### 缓存策略

> 不选择更新缓存，而是直接删除，是由于，更新操作可能会伴随着附加的操作，或者写多读少场景，每次修改都更新缓存资源浪费
>
> 为缓存设置失效时间，是保证缓存最终一致的保障
>
> 使用延迟双删除策略，保证更新数据后，缓存一定会失效
>
>  1. 使用一个单独的异步操作进行，防止阻塞造成通途量下降
>

1. 先更新数据库，再删除缓存

   > 可能造成不一致的原因，一般都是因为高并发产生
   >
   > 1. 发生的可能性不大，因为这种情况有个前提，某次写操作快于读操作

2. 先删除缓存，再更新数据库

   > 可能不一致原因：
   >
   > 1. 高并发
   > 2. 读写分离   ---> 还没同步过去，已经发生了读操作

### redis

1. string

2. list

3. set

4. zset

   > 底层通过跳跃表实现快速索引
   >
   > 底层skiplist 与dict的结合
   >
   > 利用zset 可以实现快速排序（score）

5. hash

   > 底层使用双向链表实现，所以写入快速，读取效率低

### 大流量冲击

1. 服务降级	

   > 服务降级，一般从最外层服务开始

2. 服务下线

3. 弹性扩容

4. 服务限流

### 一致性hash（nginx底层调度算法）

1. 概念

   > 单纯使用hash%N (哈希取余)，扩容时会有大量的key失效迁移，
   >
   > 按权重，生成不同的虚拟节点（每个虚拟节点hash生成时加入了上一个节点的hash，确保不一样），有了全部的hash节点后，排序形成环

2. go实现

   > golang  sort接口的search方法实现获取最合适的元素