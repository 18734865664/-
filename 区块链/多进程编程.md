# 多进程编程

## 1. 基础

### 1.1 概念

1. 串行程序

   1. 程序只能顺序的执行指令列表
2. 并发程序
   1. 利用cpu轮片，一个cpu上同时运行不同任务
   2. 并发程序中任务的执行具有不确定性
   3. 内部可以认为划分了不同的部分，每个部分都是串行执行
   4. 不同部分之间的交互：
      1. 对共享资源的访问就涉及到了同步/异步操作，需要保证同一时刻，某个资源只应该被一个程序占用
      2. 传递数据
   5. 并发到一定数量，速度就不会继续提升了，因为有的共享数据只能被串行调用，这个速度是有限的

3. 并行程序

   1. 在并行的硬件上执行
4. 多元处理

   1. 计算机中多个CPU共用一个存储器（内存），并且在同一时刻可能会有数个串行程序分别运行在不同的CPU上

#### 1.2. IPC(interprocess Communication)通讯

> 分为三大类：
>
> 1. 基于通讯的IPC方法
>    1. 以数据传输为手段
>       1. 管道（Pipe）
>          1. 可以传输字节流
>       2. 消息队列（Message Queue）
>          1. 可以传出结构化消息对象
>    2. 以内存共享为手段
>       1. 共享内存区（Shared Memory）---- 最快的一种IPC
> 2. 基于信号的IPC方法
>    1. 信号机制（Signal）
> 3. 基于同步的IPC方法
>    1. 信号灯（Semaphore）

#### 1.3 进程

> 系统分配资源的最小单位

#### 1.3.1 进程的衍生

> ​	进程可以使用系统调用fork创建若干个新的进程，前者称为父进程，后者称为子进程。初始进程为1 init进程，linux系统中，每个进程都有父进程，所有进程组成了一个树状结构，init进程是其本身的父进程，也是是孤儿进程的收养者
>
> ​	每个子进程都是源自父进程的一个副本，会获得父进程的数据段、堆、栈的副本并与父进程共享代码段。
>
> ​	每个仅从都是独立的，子进程对其副本内容的修改，不会影响父进程和兄弟进程。
>
> linux操作系统内核采用写时复制（Copy On Write,COW）技术提高进程创建效率
>
> fork()系统调用后，内核原样复制父进程的整个地址空间，并把复制的内容分配给子进程，相当耗时：
>
>  	1. 为子进程的页表分配页面
>  	2. 为子进程的页分配页面
>  	3. 初始化子进程页表
>  	4. 把父进程的页复制到子进程相应的页中
>
> 这涉及很多内存访问，很消耗cpu时间，这种复制有时候意义并不大，因为子进程会加载一个新程序并执行它，所以复制操作相当于做了无用功。
>
> COW：父进程和子进程共享内存页面而不是复制页面，只要页面被共享，就变为只读属性，当进程（父/子）试图修改页面中内容时，就会产生一个错误，将这个页复制到一个新页中，标记为可写。
>
>

#### 1.3.2 命名空间

> 对程序资源通过程序名称封装起来，使各个程序拥有相对独立的系统资源。

#### 1.3.3 进程标识

> PID  PPID

#### 1.3.4 进程状态

> 1. 可运行状态（TASK_RUNNING, R）
>    1. 随时可以运行，时机由进程调度器决定
> 2. 可中断的睡眠状态（TASK_INTERRUPTIBLE, 简称S）
>    1. 等待某个事件（IO/信号灯）
>    2. 进入对应事件的等待队列，事件发生则唤醒
> 3. 不可中断的睡眠状态（TASK_UNINTERRUNPTIBLE,j简称D）
>    1. 等待某个特定事件结束（同步状态）
>    2. 不对任何信号作出反应
> 4. 暂停/调试状态（TASK_STOPPED或TASK_TRACED,简称T）
>    1. 想进程发送SIGSTOP信号，会进入该状态，再次发送该信号，被唤醒（不可中断睡眠无法被信号唤醒）
>    2. 通常是代码调试工具发送
> 5. 僵尸状态（TASK_DEAD-EXIT_ZOMBIE,简称R）
>    1. 此时进程将要推出，主体的大部分资源已被回收，只剩下一个空壳
> 6. 退出状态（TASK_DEAD-EXIT_DEAD，简称X）
>    1. 
>
> CPU状态：初始态/就绪态/挂起态/运行态/停止态

#### 1.3.5 进程空间

> 用户进程：运行在用户空间，不能与硬件交互，每个用户进程都认为自己获得的是整个用户内存空间，进程间的虚拟内存是独立的，被映射到了不同的物理内存之上，所以互相之间不可干扰。
>
> 内核进程：运行在内核空间，可以与硬件交互
>
> 用户空间和内核空间都是内存中的一个区域，共同瓜分了操作系统能够支配的内存区域。物理内存通过MMU进行映射到虚拟内存，用户空间是0到TASK_SIZE之间的地址。虚拟内存的容量与物理内存的容量无关，
>
> 同一物理内存页允许映射到不同用户进程中，这是共享内存IPC通讯的基础
>
> 寻址：通过指针寻找内存单元的操作，指针是一个正整数，位数由计算机CPU字长决定

#### 1.3.6 系统调用

> 内核进程暴露出来的一系列接口，用户进程通过这些接口使用内核功能。
>
> 用户态/内核态：cpu有两种特权状态，正常情况下都处于用户态，再次状态下，cpu执行用户进程只能操作用户空间的内容，当用户进程发出一个系统调用的时候，会将CPU提升到内核态，而后CPU执行对应的内核函数，执行完毕后，返回到用户态。
>
> cpu处于内核态的时候，有权访问内核空间

#### 1.3.7 进程切换

> 进程切换也就是进程间上下文切换
>
> 进程切换主要由内核完成
>
> 由进程调度器控制
>
> 当CPU由执行A进程切换到执行B进程，需要保存进程A的运行时状态，并加载B的运行时状态（如果B已经运行过）

#### 1.3.8 关于同步

>  竟态条件：几个进程同时对一个资源进行访问时，极可能会造成互相的干扰，这种干扰
>
>  造成竟态条件的根本原因是，某些操作被中断了，恢复运行之后，运行环境发生了改变
>
>  原子操作（atomic operation）：执行过程中不能被打断的操作，所有的系统调用都是原子操作
>
>  临界区（critical section）：只能被串行化的访问或执行的某个资源或某段代码
>
>  原子操作是不可中断的，临界区可以中断，但只能串行执行/访问
>
>  原子操作需要一个单独的汇编指令代表，需要芯片级的支持，现在的CPU（单核/多核）大多都支持这一操作，但有个问题，一旦原子操作在执行中一直不结束，外部信号也无法终止其执行操作，所以现在内核只提供对二进制位和整数的原子操作（细粒度原子操作）
>
>  互斥（mutex）：相较于原子操作，形成临界区的操作更为合适

#### 1.3.9 管道

> 管道（Pipe）是一种半双工（单向）的通讯方式。只能用于父子进程/兄弟进程之间的通讯
>
> shell会为每一条命令生成一个进程，管道就是为了进程间通讯
>
> 缺陷是只能单向通讯/通讯双方关系上严格限制
>
> 单向管道输入结束后，记得关闭管道，管道一端调用close函数，不影响另一端写入/读取操作
>
> linux命令：mkfifo       //生成一个命名管道，可以用来实现io多路复用
>
> go模块：os.Pipe()

#### 1.3.10 信号（Signal，操作系统信号）

> 本质是用软件模拟硬件的中断机制
>
> linux系统有62种信号，1-31 属于标准信号，34-64属于实时信号，对同一个进程来说，且不同标准信号执行顺序不确定；同一个标准信号只会被记录并处理一次，实时信号则可以多次处理同一信号
>
> 进程响应信号的方式：忽略/捕捉/执行默认操作
>
> go实现：syscall.Signal

#### 1.3.11 Socket

> 通过网络连接来使两个或多个的进程建立通讯并相互传递数据
>
> func Listen(net, laddr string)(Listener, error)   // 获取一个监听器
>
> Listener.Accept()    //调用后阻塞，直到接收到一个TCP连接
>
> Dail(network, address string)(Conn, error)     //客户端程序   // 端口由系统分配
>
> Dail超时有两种情况：
>
>  	1. DNS解析超时
>  	2. 与服务端交互超时
>
> go语言的socket编程底层获取的是一个非阻塞式的Socket实例，也就是Socket接口在TCP连接上的数据读取操作是非阻塞的
>
> 进行tcp读写操作的时候，即使缓存区满了（写）/缓存区空了（读），也不会产生阻塞，而是返回一个程序会忽略的错误，并且重新尝试，这种特性叫做部分读/部分写
>
> 底层的socket  accept也是非阻塞的
>
> go语言将socket进行了封装，把大部分非阻塞式写特性进行了屏蔽，相关API把数据全部写入Socket缓存区之后才返回，除非发生了某种错误。把非阻塞读特性呈现给调用者，调用者需要对读操作进行额外处理（因为网络中传输的都是字节流，系统无法自动识别消息边界）
>
>

### 1.4 线程

> 线程可以看作某个进程中的一个控制流
>
> 一个进程中至少会包含一个线程，该线程随进程的创建而创建，称为主线程
>
> 线程可能独立于进程存在，所以其生命周期小于等于进程的生命周期
>
> 每个线程拥有自己的线程栈，用于存储自己的私有数据
>
> 每个进程中的线程共享进程的资源：代码段/数据段/堆/信号处理函数/进程的描述符，所以创建一个线程消耗远小于进程
>
> 同一个进程中的线程运行的肯定是同一个程序（可能是不同的代码段）

### 1.4.1 线程标识

> 每个线程由属于自己的ID，线程ID简称TID
>
> 线程ID在系统范围内可以不是唯一的，但在进程中必须是唯一的（linux系统中的进程实现决定了系统范围内TID的唯一性）

#### 1.4.2 线程间控制

> 同一进程中的线程地位是相同的，也就是说任何线程都可以对其所属进程中其他线程进行有限的管理：
>
> 1. 创建线程
> 2. 终止线程  -- 终止信号不会对发送发阻塞
> 3. 连接线程 -- 一个可被连接的线程，被终止时就必须被连接，否则就会编程僵尸进程
> 4. 分离线程 -- 分离线程的意思是，被执行线程不再可连接，便于系统回收销毁线程，处理分离状态的线程不能被转变为可连接状态，但可以接收终止信号
>
> 对线程自身的控制
>
> 1. 终止
>    1. 主线程中调用return/exit函数，所有的线程都会终止
>    2. 主线程中调用了pthread_exit，主线程终止，其他线程正常运行
> 2. 分离
>
> 线程状态：就绪态/运行态/睡眠态/僵尸态/终止态
>
> 处于终止态的线程才能被操作系统内核回收
>
> 转入睡眠态的条件：

#### 1.4.3 线程的调度

> 线程调度：也称为线程间的上下文切换
>
> 线程的执行总是趋向于CPU受限或I/O受限
>
> 线程获取cpu轮片的优先级由两部分组成
>
> 1. 动态优先级：由调度器预测线程倾向于IO操作还是CPU操作，调度器会将IO操作倾向的线程动态优先级调高，为了高IO线程能早点执行。动态优先级实在静态优先级的基础上调整得出的
> 2. 静态优先级：静态优先级由应用程序指定，如果程序未被指定，则默认指定为0，调度器不会调整静态优先级
>
> 调度器维护两个运行阵列（动态优先级由高到低的多个链表，每个链表包含想同优先级的线程，新加入阵列的进程，放入对应链表的末尾）
>
> 1. 激活的优先级阵列，等待运行的线程
> 2. 过期的优先级阵列，释放CPU轮片的线程
>
> 当激活优先级阵列中没有待运行线程时，两个阵列互换角色
>
> 调度器会稍稍提高被唤醒的线程动态优先级
>
> 调度器还负责多核CPU之间的负载调动（会尽量维持同一个线程在同一个CPU上执行，为了提高缓存命中率）

#### 1.4.4 线程实现模型

> 线程实现模型之间的差异主要在于线程与内核调度实体（kernel Scheduling Entity，简称KSE）之间的对应关系
>
> 1. 用户级线程模型
>    1. 线程库与内核无关，内核调度器不负责此类线程的调度，线程调度由用户级程序控制，所以不存在用户态/内核态的切换
>    2. 所以用户级线程在运行速度上有优势
> 2. 内核级线程模型
>    1. 该模型下的线程由内核负责管理，创建终止等管理动作由内核提供的系统调用完成
>    2. 内核可以分别对每个线程进行调度：一个线程对应一个KSE，所以又称为1：1的线程实现
> 3. 两级线程模型
>    1. 多对多的线程实现（M:N）
>    2. 一个进程与多个KSE相关联
>    3. 系统创建多个KSE，然后通过KSE对用户级线程进行调度

#### 1.4.5 线程间同步

> 同步，就是为了让它们更好的协同工作或者维持共享数据的一致性
>
> 设为常量
>
> 互斥量
>
> 读写锁
>
> 满足要求的前提下最小化互斥量的访问权限
>
> 试锁定机制：
>
>  	1. 可能造成死锁的两个互斥量，程序锁定A后，尝试锁定B，如果成功，则解锁B，后执行代码，如果试锁定B失败，则释放A后再次走流程
>
> 固定顺序锁定：
>
> 1. 可能造成死锁的两个互斥量，程序总是先锁定A，再锁定B，防止死锁
>
> 防止死锁，最有效的手段是保持数据的独立性
>
> 条件变量：
>
>  	1. wait
>  	2. signal
>  	3. broadcast

### 1.5 go并发编程

> 标语：不要用共享内存的方式通信，作为代替，应该以通信作为手段共享内存
>
> 共享内存的方式进行数据共享，并发控制问题很复杂

#### 1.5.1 MPG模型

> 简单的看，goroutine是一种两级线程模型
>
> M：Machine，代表一个内核线程，有一个全局M列表
>
>  	1. 初始化go运行环境后，默认允许10000个M，事实上由于系统中各种限制，往往到不了这个数量
>
> P：Processor，代表M所需的上下文环境
>
>  	1. P是使G能够在M中运行的关键
>  	2. M与P之间关联的建立与断开，类似于任务在CPU中调度过程
>  	3. 一个M因正运行的G进入阻塞状态的时候，会中断与P之间的关联，由另一个M与之关联继续执行其中的G
>  	4. runtime.GOMAXPROCS  设置最大的P数量，默认值为1
>       ​	1. 最大值是硬件上限（256）
>       ​	2. 设置后，所有的P都会暂时停止，所以要设置就在main中早点调用
>
> G：Goroutine，代表一段需要被并发执行的Go语言代码的封装
>
> 一个G的执行需要M和P的支持，一个M与一个P关联之后（内核线程+上下文环境）就形成了一个有效的G执行环境，每个P都包含一个可运行的G队列（runq）
>
> 对应关系：
>
> 1. 一个M对应一个内核空间中KSE，整个生命周期只会与一个KSE关联
> 2. M与P之间的关联是随机的，M中有一个属性保存现在正关联的P
> 3. P中有个G的运行队列
> 4. M中有一个属性，保存现在M上正运行的G

### 1.6 channel

> type myInt  chan int 
>
> myInt := make(chan int, cap)
>
> cap设为0，或不设置，表示初始化的是一个无缓存的通道
>
> data, ok <- myInt
>
> 缓冲通道与非缓存通道之间最大的差别是，非缓存通道往通道中存放数据的时候，是异步的，发送方等接收方收到了，才解除阻塞。缓存通道存放数据后，直接开启下一步操作
>
> select 语句：
>
> select {
>
> case data, ok <- myInt:
>
> default:
>
> }
>
> 这里要注意，如果select外面加一层for，直接使用break只是退出select，而不是退出for。
>
> 收发双方都有并发需求的时候，使用有缓存的通道

### 1.6 同步

#### 1.6.1 互斥量（mutex）

#### 1.6.2 读写锁

#### 1.6.3 条件变量

#### 1.6.4 原子性操作

> 在某些时候，比使用互斥量更适合
>
> 是直接对内存进行操作（通过特殊的CPU指令，执行的过程中不会被打断）
>
> sync/atomic
>
> 类型：int32/int64/uint32/uint64/uintptr/unsafe.Pointer
>
> 操作：
>
> 1. 增或减、
>    1. 函数以Add开头，如：atomic.AddUint32(ptr, uint32)
> 2. 比较并交换、
>    1. 函数以CompareAndSwap开头，CompareAndSwapUint32(ptr, old, new)
>    2. 会先校验old是否于原值相等，不相等则不替换 
> 3. 载入、
>    1. 函数以Load开头，如num :=  LoadUint32(ptr)
> 4. 存储、
>    1. 函数以Store开头，
>    2. 如StoreUint32(otr, value)，这是个赋值过程，与compareAndSwap作区分，不关心前值是什么
> 5. 交换
>    1. 函数以Swap开头，不关心旧址，会直接设置新值，会返回就值
>    2. old := SwapUint32(ptr, new)

#### 1.6.5 只执行一次

> var once sync.Once
>
> once.Do(func)
>
> 程序的生命周期中，只有第一次传递给Do的函数会被执行

#### 1.6.6 WaitGroup

> wg.Add(n)
>
> wg.Done  == wg.Add(-1)
>
> wg.Wait()

#### 1.6.7 临时变量池

> sync.Pool
>
> 可以看作是存放可被重复利用的值的容器，并发安全，自动伸缩，高效
>
> 垃圾回收时会清空临时变量池，其生命周期就是到下一次垃圾回收时间
>
> pool中的变量随时可能被回收，且不会通过调用方
>
> 方法：
>
> 1. Get()
> 2. Put()